{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path = \"../Data_Sources/Data_Cleaned/Predictions/Segmented_Visitor_Demand_Prediction.csv\"\n",
    "predictions_df = pd.read_csv(predictions_path)\n",
    "\n",
    "modelling_path = \"../Data_Sources/Data_Cleaned/Modelling/Table_for_modelling.csv\"\n",
    "df = pd.read_csv(modelling_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_merge = [\n",
    "    'Recreatief NL_pred', 'Recreatief NL_actual',\n",
    "    'Recreatief Buitenland_pred', 'Recreatief Buitenland_actual', \n",
    "    'PO_pred', 'PO_actual',\n",
    "    'VO_pred', 'VO_actual',\n",
    "    'Student_pred', 'Student_actual',\n",
    "    'Extern_pred', 'Extern_actual', \n",
    "    'Total Visitors_pred', 'Total Visitors_actual',\n",
    "    'Date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.merge(\n",
    "            predictions_df[cols_to_merge], \n",
    "            on='Date', \n",
    "            how='left'\n",
    "        )\n",
    "new_df = merged_df.iloc[30:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Crew Size Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrewSizePredictionModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_names = None\n",
    "        self.class_mapping = {}\n",
    "        \n",
    "        # Define crew size categories in order of capacity\n",
    "        self.crew_size_order = ['Gesloten', 'Gesloten maandag', 'A min', 'A', 'B', 'C', 'D']\n",
    "        \n",
    "    def clean_crew_size_data(self, df):\n",
    "        \"\"\"Clean and prepare crew size data\"\"\"\n",
    "        df_clean = df.copy()\n",
    "        \n",
    "        # Handle NaN values in maat_visitors\n",
    "        # You might want to fill these based on business logic\n",
    "        df_clean['maat_visitors'] = df_clean['maat_visitors'].fillna('Unknown')\n",
    "        \n",
    "        # Create a mapping for crew sizes to numerical values for ordering\n",
    "        crew_mapping = {size: idx for idx, size in enumerate(self.crew_size_order)}\n",
    "        crew_mapping['Unknown'] = -1  # For NaN values\n",
    "        \n",
    "        df_clean['crew_size_numeric'] = df_clean['maat_visitors'].map(crew_mapping)\n",
    "        \n",
    "        print(\"Crew size distribution:\")\n",
    "        print(df_clean['maat_visitors'].value_counts())\n",
    "        \n",
    "        return df_clean\n",
    "    \n",
    "    def engineer_crew_features(self, df):\n",
    "        \"\"\"Engineer features specifically for crew size prediction with rolling and lagged features\"\"\"\n",
    "        df_features = df.copy()\n",
    "        \n",
    "        # Ensure Date is datetime\n",
    "        if 'Date' in df.columns:\n",
    "            df_features['Date'] = pd.to_datetime(df_features['Date'])\n",
    "            df_features = df_features.sort_values('Date').reset_index(drop=True)\n",
    "        \n",
    "        # Calculate visitor type ratios\n",
    "        if 'Total Visitors_pred' in df.columns:\n",
    "            total_pred = df_features['Total Visitors_pred']\n",
    "            df_features['recreatief_nl_ratio'] = df_features['Recreatief NL_pred'] / (total_pred + 1)\n",
    "            df_features['recreatief_buitenland_ratio'] = df_features['Recreatief Buitenland_pred'] / (total_pred + 1)\n",
    "            df_features['educational_ratio'] = (\n",
    "                df_features['PO_pred'] + df_features['VO_pred'] + df_features['Student_pred']\n",
    "            ) / (total_pred + 1)\n",
    "            df_features['extern_ratio'] = df_features['Extern_pred'] / (total_pred + 1)\n",
    "        \n",
    "        # Time-based features\n",
    "        if 'Date' in df.columns:\n",
    "            df_features['day_of_week'] = df_features['Date'].dt.dayofweek\n",
    "            df_features['is_weekend'] = df_features['day_of_week'].isin([5, 6]).astype(int)\n",
    "            df_features['is_monday'] = (df_features['day_of_week'] == 0).astype(int)\n",
    "            df_features['month'] = df_features['Date'].dt.month\n",
    "            df_features['is_summer'] = df_features['month'].isin([6, 7, 8]).astype(int)\n",
    "        \n",
    "        # Weather impact on crew needs\n",
    "        if 'MeanTemp_C' in df.columns and 'Precipitation_mm' in df.columns:\n",
    "            df_features['good_weather'] = (\n",
    "                (df_features['MeanTemp_C'] > 15) & \n",
    "                (df_features['Precipitation_mm'] < 1)\n",
    "            ).astype(int)\n",
    "            df_features['bad_weather'] = (\n",
    "                (df_features['MeanTemp_C'] < 10) | \n",
    "                (df_features['Precipitation_mm'] > 5)\n",
    "            ).astype(int)\n",
    "        \n",
    "        # Holiday and special events\n",
    "        holiday_cols = [col for col in df.columns if 'holiday' in col.lower()]\n",
    "        if holiday_cols:\n",
    "            df_features['any_holiday'] = df_features[holiday_cols].max(axis=1)\n",
    "        \n",
    "        # Operational factors\n",
    "        if 'is_open' in df.columns:\n",
    "            df_features['is_open'] = df_features['is_open'].fillna(1)\n",
    "        \n",
    "        # Museum capacity pressure\n",
    "        if 'Total Visitors_pred' in df.columns:\n",
    "            df_features['high_capacity_day'] = (df_features['Total Visitors_pred'] > df_features['Total Visitors_pred'].quantile(0.8)).astype(int)\n",
    "            df_features['low_capacity_day'] = (df_features['Total Visitors_pred'] < df_features['Total Visitors_pred'].quantile(0.2)).astype(int)\n",
    "        \n",
    "        # === LAGGED FEATURES ===\n",
    "        # Visitor prediction lags\n",
    "        visitor_pred_cols = [col for col in df_features.columns if col.endswith('_pred')]\n",
    "        lags = [1, 7, 14]  # 1 day, 1 week, 2 weeks\n",
    "        \n",
    "        for lag in lags:\n",
    "            for col in visitor_pred_cols:\n",
    "                df_features[f'{col}_lag_{lag}'] = df_features[col].shift(lag)\n",
    "            \n",
    "            # Total visitors lag\n",
    "            if 'Total Visitors_pred' in df.columns:\n",
    "                df_features[f'total_visitors_lag_{lag}'] = df_features['Total Visitors_pred'].shift(lag)\n",
    "        \n",
    "        # Historical crew size patterns (if available)\n",
    "        if 'maat_visitors' in df.columns:\n",
    "            # Encode crew sizes numerically for lagged features\n",
    "            crew_size_mapping = {\n",
    "                'Gesloten': 0,\n",
    "                'Gesloten maandag': 1, \n",
    "                'A min': 2,\n",
    "                'A': 3,\n",
    "                'B': 4,\n",
    "                'C': 5,\n",
    "                'D': 6\n",
    "            }\n",
    "            \n",
    "            df_features['crew_size_numeric'] = df_features['maat_visitors'].map(crew_size_mapping)\n",
    "            df_features['crew_size_numeric'] = df_features['crew_size_numeric'].fillna(-1)\n",
    "            \n",
    "            # Lagged crew sizes\n",
    "            for lag in lags:\n",
    "                df_features[f'crew_size_lag_{lag}'] = df_features['crew_size_numeric'].shift(lag)\n",
    "            \n",
    "            # Same day last week crew size\n",
    "            df_features['crew_size_last_week'] = df_features['crew_size_numeric'].shift(7)\n",
    "        \n",
    "        # === ROLLING FEATURES ===\n",
    "        windows = [7, 14]  # 1 week, 2 weeks\n",
    "        \n",
    "        # Rolling visitor statistics\n",
    "        for window in windows:\n",
    "            for col in visitor_pred_cols:\n",
    "                df_features[f'{col}_rolling_mean_{window}'] = df_features[col].shift(1).rolling(window=window).mean()\n",
    "                df_features[f'{col}_rolling_std_{window}'] = df_features[col].shift(1).rolling(window=window).std()\n",
    "                df_features[f'{col}_rolling_max_{window}'] = df_features[col].shift(1).rolling(window=window).max()\n",
    "        \n",
    "        # Rolling crew size patterns (mode for categorical data)\n",
    "        if 'crew_size_numeric' in df_features.columns:\n",
    "            for window in windows:\n",
    "                # Most frequent crew size (mode) using numeric values\n",
    "                def numeric_mode(x):\n",
    "                    \"\"\"Calculate mode for numeric crew sizes\"\"\"\n",
    "                    if len(x) == 0 or x.isna().all():\n",
    "                        return -1  # Unknown\n",
    "                    mode_result = x.mode()\n",
    "                    return mode_result.iloc[0] if len(mode_result) > 0 else -1\n",
    "                \n",
    "                df_features[f'crew_mode_numeric_{window}'] = (\n",
    "                    df_features['crew_size_numeric']\n",
    "                    .shift(1)\n",
    "                    .rolling(window=window)\n",
    "                    .apply(numeric_mode, raw=False)\n",
    "                )\n",
    "                \n",
    "                # Crew size stability (consistency)\n",
    "                def crew_stability(x):\n",
    "                    \"\"\"Calculate how consistent crew sizing has been\"\"\"\n",
    "                    if len(x) == 0 or x.isna().all():\n",
    "                        return 0\n",
    "                    mode_result = x.mode()\n",
    "                    if len(mode_result) == 0:\n",
    "                        return 0\n",
    "                    most_common = mode_result.iloc[0]\n",
    "                    return (x == most_common).mean()\n",
    "                \n",
    "                df_features[f'crew_stability_{window}'] = (\n",
    "                    df_features['crew_size_numeric']\n",
    "                    .shift(1)\n",
    "                    .rolling(window=window)\n",
    "                    .apply(crew_stability, raw=False)\n",
    "                )\n",
    "                \n",
    "                # Average crew size level over window\n",
    "                df_features[f'crew_avg_{window}'] = (\n",
    "                    df_features['crew_size_numeric']\n",
    "                    .shift(1)\n",
    "                    .rolling(window=window)\n",
    "                    .mean()\n",
    "                )\n",
    "                \n",
    "                # Crew size trend (is it increasing/decreasing?)\n",
    "                df_features[f'crew_trend_{window}'] = (\n",
    "                    df_features['crew_size_numeric'] - \n",
    "                    df_features['crew_size_numeric'].shift(window)\n",
    "                )\n",
    "        \n",
    "        # Rolling weather patterns\n",
    "        if 'good_weather' in df_features.columns:\n",
    "            for window in windows:\n",
    "                df_features[f'good_weather_freq_{window}'] = (\n",
    "                    df_features['good_weather']\n",
    "                    .shift(1)\n",
    "                    .rolling(window=window)\n",
    "                    .mean()\n",
    "                )\n",
    "        \n",
    "        # Rolling holiday density\n",
    "        if 'any_holiday' in df_features.columns:\n",
    "            for window in windows:\n",
    "                df_features[f'holiday_density_{window}'] = (\n",
    "                    df_features['any_holiday']\n",
    "                    .shift(1)\n",
    "                    .rolling(window=window)\n",
    "                    .mean()\n",
    "                )\n",
    "        \n",
    "        # === SEASONAL PATTERNS ===\n",
    "        if 'Date' in df.columns:\n",
    "            # Same weekday patterns\n",
    "            df_features['weekday'] = df_features['Date'].dt.dayofweek\n",
    "            \n",
    "            # Average crew size for this weekday in the past (if available)\n",
    "            if 'crew_size_numeric' in df_features.columns:\n",
    "                weekday_crew_avg = df_features.groupby('weekday')['crew_size_numeric'].expanding().mean()\n",
    "                df_features['weekday_crew_avg'] = weekday_crew_avg.reset_index(level=0, drop=True)\n",
    "                df_features['weekday_crew_avg'] = df_features['weekday_crew_avg'].shift(1)  # Don't use current day\n",
    "        \n",
    "        # === INTERACTION FEATURES ===\n",
    "        # High visitor days with weather\n",
    "        if 'Total Visitors_pred' in df_features.columns and 'good_weather' in df_features.columns:\n",
    "            df_features['high_visitors_good_weather'] = (\n",
    "                df_features['high_capacity_day'] * df_features['good_weather']\n",
    "            )\n",
    "        \n",
    "        # Weekend + holiday interaction\n",
    "        if 'is_weekend' in df_features.columns and 'any_holiday' in df_features.columns:\n",
    "            df_features['weekend_holiday'] = (\n",
    "                df_features['is_weekend'] * df_features['any_holiday']\n",
    "            )\n",
    "        \n",
    "        # === RECENT TREND FEATURES ===\n",
    "        # Visitor trend (is it increasing/decreasing?)\n",
    "        if 'Total Visitors_pred' in df_features.columns:\n",
    "            df_features['visitor_trend_3d'] = (\n",
    "                df_features['Total Visitors_pred'] - \n",
    "                df_features['Total Visitors_pred'].shift(3)\n",
    "            )\n",
    "            df_features['visitor_trend_7d'] = (\n",
    "                df_features['Total Visitors_pred'] - \n",
    "                df_features['Total Visitors_pred'].shift(7)\n",
    "            )\n",
    "        \n",
    "        print(f\"Feature engineering complete. Shape: {df_features.shape}\")\n",
    "        print(f\"Added lagged and rolling features for crew size prediction\")\n",
    "        \n",
    "        return df_features\n",
    "    \n",
    "    def select_features(self, df):\n",
    "        \"\"\"Select relevant features for crew size prediction including lagged and rolling features\"\"\"\n",
    "        # Primary features: predicted visitor numbers\n",
    "        feature_cols = [col for col in df.columns if col.endswith('_pred')]\n",
    "        \n",
    "        # Basic engineered features\n",
    "        engineered_features = [\n",
    "            'recreatief_nl_ratio', 'recreatief_buitenland_ratio',\n",
    "            'educational_ratio', 'extern_ratio', 'day_of_week', 'is_weekend', \n",
    "            'is_monday', 'month', 'is_summer', 'good_weather', 'bad_weather',\n",
    "            'any_holiday', 'is_open', 'high_capacity_day', 'low_capacity_day'\n",
    "        ]\n",
    "        \n",
    "        # Weather and operational features\n",
    "        additional_features = [\n",
    "            'MeanTemp_C', 'Precipitation_mm', 'school_holiday', 'public_holiday',\n",
    "            'Events_in_Ams', 'hotel_occupancy_index', 'peak_season_flag'\n",
    "        ]\n",
    "        \n",
    "        # === LAGGED FEATURES ===\n",
    "        lagged_features = []\n",
    "        \n",
    "        # Visitor prediction lags (1, 7, 14 days)\n",
    "        visitor_pred_base = [col for col in df.columns if col.endswith('_pred')]\n",
    "        for base_col in visitor_pred_base:\n",
    "            for lag in [1, 7, 14]:\n",
    "                lagged_features.append(f'{base_col}_lag_{lag}')\n",
    "        \n",
    "        # Total visitors lags\n",
    "        for lag in [1, 7, 14]:\n",
    "            lagged_features.append(f'total_visitors_lag_{lag}')\n",
    "        \n",
    "        # Historical crew size lags (if available)\n",
    "        crew_lag_features = [\n",
    "            'crew_size_lag_1', 'crew_size_lag_7', 'crew_size_lag_14',\n",
    "            'crew_size_last_week'\n",
    "        ]\n",
    "        lagged_features.extend(crew_lag_features)\n",
    "        \n",
    "        # === ROLLING FEATURES ===\n",
    "        rolling_features = []\n",
    "        \n",
    "        # Rolling visitor statistics (7, 14, 30 day windows)\n",
    "        for window in [7, 14, 30]:\n",
    "            # For each visitor prediction column\n",
    "            for base_col in visitor_pred_base:\n",
    "                rolling_features.extend([\n",
    "                    f'{base_col}_rolling_mean_{window}',\n",
    "                    f'{base_col}_rolling_std_{window}',\n",
    "                    f'{base_col}_rolling_max_{window}'\n",
    "                ])\n",
    "        \n",
    "        # Rolling crew size patterns\n",
    "        crew_rolling_features = []\n",
    "        for window in [7, 14, 30]:\n",
    "            crew_rolling_features.extend([\n",
    "                f'crew_mode_numeric_{window}',    # Most frequent crew size\n",
    "                f'crew_stability_{window}',       # How consistent crew sizing was\n",
    "            ])\n",
    "        rolling_features.extend(crew_rolling_features)\n",
    "        \n",
    "        # Rolling weather and holiday patterns\n",
    "        weather_rolling_features = []\n",
    "        for window in [7, 14, 30]:\n",
    "            weather_rolling_features.extend([\n",
    "                f'good_weather_freq_{window}',    # Good weather frequency\n",
    "                f'holiday_density_{window}',      # Holiday density\n",
    "            ])\n",
    "        rolling_features.extend(weather_rolling_features)\n",
    "        \n",
    "        # === SEASONAL PATTERN FEATURES ===\n",
    "        seasonal_features = [\n",
    "            'weekday_crew_avg',               # Average crew size for this weekday\n",
    "        ]\n",
    "        \n",
    "        # === INTERACTION FEATURES ===\n",
    "        interaction_features = [\n",
    "            'high_visitors_good_weather',     # High capacity + good weather\n",
    "            'weekend_holiday',                # Weekend + holiday interaction\n",
    "        ]\n",
    "        \n",
    "        # === TREND FEATURES ===\n",
    "        trend_features = [\n",
    "            'visitor_trend_3d',               # 3-day visitor change\n",
    "            'visitor_trend_7d',               # 7-day visitor change\n",
    "        ]\n",
    "        \n",
    "        # === COMBINE ALL FEATURE CATEGORIES ===\n",
    "        all_features = (\n",
    "            feature_cols +                    # Visitor predictions\n",
    "            engineered_features +             # Basic engineered features\n",
    "            additional_features +             # Weather/operational features\n",
    "            lagged_features +                 # Lagged features\n",
    "            rolling_features +                # Rolling window features\n",
    "            seasonal_features +               # Seasonal patterns\n",
    "            interaction_features +            # Feature interactions\n",
    "            trend_features                    # Trend features\n",
    "        )\n",
    "        \n",
    "        # Filter to only include features that actually exist in the dataframe\n",
    "        selected_features = [col for col in all_features if col in df.columns]\n",
    "        \n",
    "        # Print feature summary\n",
    "        feature_categories = {\n",
    "            'Visitor Predictions': [col for col in feature_cols if col in df.columns],\n",
    "            'Basic Features': [col for col in engineered_features if col in df.columns],\n",
    "            'Weather/Operational': [col for col in additional_features if col in df.columns],\n",
    "            'Lagged Features': [col for col in lagged_features if col in df.columns],\n",
    "            'Rolling Features': [col for col in rolling_features if col in df.columns],\n",
    "            'Seasonal Features': [col for col in seasonal_features if col in df.columns],\n",
    "            'Interaction Features': [col for col in interaction_features if col in df.columns],\n",
    "            'Trend Features': [col for col in trend_features if col in df.columns],\n",
    "        }\n",
    "        \n",
    "        print(\"=== FEATURE SELECTION SUMMARY ===\")\n",
    "        for category, features in feature_categories.items():\n",
    "            print(f\"{category}: {len(features)} features\")\n",
    "            if len(features) <= 5:  # Show all if 5 or fewer\n",
    "                print(f\"  {features}\")\n",
    "            else:  # Show first 3 and last 2 if more than 5\n",
    "                print(f\"  {features[:3]} ... {features[-2:]}\")\n",
    "        \n",
    "        print(f\"\\nTotal selected features: {len(selected_features)}\")\n",
    "        \n",
    "        return selected_features\n",
    "    \n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        # Clean crew size data\n",
    "        df_clean = self.clean_crew_size_data(df)\n",
    "        \n",
    "        # Remove rows where museum is closed or crew size is unknown\n",
    "        # You might want to predict these separately\n",
    "        df_model = df_clean[\n",
    "            (~df_clean['maat_visitors'].isin(['Gesloten', 'Unknown', 'Gesloten maandag'])) &\n",
    "            (df_clean['is_open'] == 1)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"Training data shape after filtering: {df_model.shape}\")\n",
    "        print(\"Remaining crew size distribution:\")\n",
    "        print(df_model['maat_visitors'].value_counts())\n",
    "        \n",
    "        # Engineer features\n",
    "        df_features = self.engineer_crew_features(df_model)\n",
    "        \n",
    "        # Select features\n",
    "        feature_cols = self.select_features(df_features)\n",
    "        \n",
    "        X = df_features[feature_cols]\n",
    "        y = df_features['maat_visitors']\n",
    "        \n",
    "        # Handle any remaining NaN values\n",
    "        X = X.fillna(X.median())\n",
    "        \n",
    "        return X, y, feature_cols\n",
    "\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt='d',\n",
    "            xticklabels=self.label_encoder.classes_,\n",
    "            yticklabels=self.label_encoder.classes_,\n",
    "            cmap='Blues'\n",
    "        )\n",
    "        plt.title('Confusion Matrix - Crew Size Prediction')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def train(self, df):\n",
    "        \"\"\"Improved training with regularization\"\"\"\n",
    "        X, y, feature_cols = self.prepare_data(df)\n",
    "        self.feature_names = feature_cols\n",
    "        \n",
    "        # Encode labels\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        # Split data first\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Feature selection to reduce overfitting\n",
    "        selector = SelectKBest(score_func=f_classif, k=min(20, len(feature_cols)))\n",
    "        X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "        X_test_selected = selector.transform(X_test_scaled)\n",
    "        \n",
    "        # Store selector for later use\n",
    "        self.feature_selector = selector\n",
    "        self.selected_features = [feature_cols[i] for i in selector.get_support(indices=True)]\n",
    "        print(f\"Selected {len(self.selected_features)} features: {self.selected_features}\")\n",
    "        \n",
    "        # More regularized model (reduced complexity)\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            n_estimators=200,     # Reduced from 300\n",
    "            learning_rate=0.08,   # Slightly higher learning rate\n",
    "            max_depth=3,          # Reduced depth\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.7, # Reduced feature sampling\n",
    "            min_child_weight=5,   # Increased regularization\n",
    "            reg_alpha=0.2,        # Increased L1 regularization\n",
    "            reg_lambda=1.5,       # Increased L2 regularization\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        \n",
    "        # Simple training without early stopping\n",
    "        self.model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred_test = self.model.predict(X_test_selected)\n",
    "        y_pred_train = self.model.predict(X_train_selected)\n",
    "\n",
    "        y_true_combined = np.concatenate([y_test, y_train])\n",
    "        y_pred_combined = np.concatenate([y_pred_test, y_pred_train])\n",
    "\n",
    "        self.plot_confusion_matrix(y_true_combined, y_pred_combined)\n",
    "        \n",
    "        print(f\"\\nTrain Accuracy: {accuracy_score(y_train, y_pred_train):.4f}\")\n",
    "        print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "        print(f\"Overfitting Gap: {accuracy_score(y_train, y_pred_train) - accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "        \n",
    "        # Print classification report\n",
    "        print(\"\\nTest Set Classification Report:\")\n",
    "        print(classification_report(\n",
    "            y_test, y_pred_test, \n",
    "            target_names=self.label_encoder.classes_\n",
    "        ))\n",
    "        \n",
    "        # Plot feature importance\n",
    "        self.plot_feature_importance_selected()\n",
    "        \n",
    "        return X_train_selected, X_test_selected, y_train, y_test, y_pred_test\n",
    "    \n",
    "    \n",
    "    def plot_feature_importance_selected(self, top_n=15):\n",
    "        \"\"\"Plot feature importance for selected features\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.selected_features,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(\n",
    "            data=importance_df.head(top_n),\n",
    "            x='importance',\n",
    "            y='feature'\n",
    "        )\n",
    "        plt.title('Feature Importance - Selected Features Only')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    def predict(self, df):\n",
    "        \"\"\"Predict with feature selection\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet. Call train() first.\")\n",
    "        \n",
    "        # Engineer features\n",
    "        df_features = self.engineer_crew_features(df)\n",
    "        \n",
    "        # Select original features\n",
    "        X = df_features[self.feature_names]\n",
    "        X = X.fillna(X.median())\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Apply feature selection\n",
    "        X_selected = self.feature_selector.transform(X_scaled)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_encoded = self.model.predict(X_selected)\n",
    "        y_pred_proba = self.model.predict_proba(X_selected)\n",
    "        \n",
    "        # Decode predictions\n",
    "        y_pred = self.label_encoder.inverse_transform(y_pred_encoded)\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'Date': df['Date'] if 'Date' in df.columns else range(len(df)),\n",
    "            'predicted_crew_size': y_pred,\n",
    "            'prediction_confidence': y_pred_proba.max(axis=1)\n",
    "        })\n",
    "        \n",
    "        # Add probability for each class\n",
    "        for i, class_name in enumerate(self.label_encoder.classes_):\n",
    "            results[f'prob_{class_name}'] = y_pred_proba[:, i]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "\n",
    "    def analyze_crew_patterns(self, df):\n",
    "        \"\"\"Analyze patterns in crew size assignments\"\"\"\n",
    "        df_clean = self.clean_crew_size_data(df)\n",
    "        \n",
    "        # Visitor count vs crew size analysis\n",
    "        if 'Total Visitors_actual' in df.columns:\n",
    "            crew_visitor_analysis = df_clean.groupby('maat_visitors').agg({\n",
    "                'Total Visitors_actual': ['mean', 'median', 'std', 'min', 'max'],\n",
    "                'Date': 'count'\n",
    "            }).round(2)\n",
    "            \n",
    "            print(\"Visitor Statistics by Crew Size:\")\n",
    "            print(crew_visitor_analysis)\n",
    "        \n",
    "        # Day of week patterns\n",
    "        if 'Date' in df.columns:\n",
    "            df_clean['Date'] = pd.to_datetime(df_clean['Date'])\n",
    "            df_clean['day_of_week'] = df_clean['Date'].dt.day_name()\n",
    "            \n",
    "            day_crew_crosstab = pd.crosstab(\n",
    "                df_clean['day_of_week'], \n",
    "                df_clean['maat_visitors'], \n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            \n",
    "            print(\"\\nCrew Size Distribution by Day of Week (%):\")\n",
    "            print(day_crew_crosstab.round(1))\n",
    "        \n",
    "        return crew_visitor_analysis if 'Total Visitors_actual' in df.columns else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    crew_model = CrewSizePredictionModel()\n",
    "\n",
    "    crew_model.analyze_crew_patterns(df)\n",
    "\n",
    "    crew_model.train(df)\n",
    "\n",
    "    predictions = crew_model.predict(df)\n",
    "    predictions.to_csv(\"../Data_Sources/Data_Cleaned/Predictions/Crew_Size_Predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
