{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, IsolationForest\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, mean_squared_error, make_scorer, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import BayesianRidge, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, accuracy_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "file_path = \"../Data_Sources/Data_Cleaned/Table_for_modelling\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_advanced_features(df):\n",
    "    # Create interaction features for strong predictors\n",
    "    df['recreational_total'] = df['Recreatief NL'] + df['Recreatief Buitenland']\n",
    "    df['education_total'] = df['VO'] + df['Student'] + df['PO']\n",
    "    \n",
    "    # Create seasonal features\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['season'] = df['Date'].dt.month.map({12:1, 1:1, 2:1,  # Winter\n",
    "                                           3:2, 4:2, 5:2,    # Spring\n",
    "                                           6:3, 7:3, 8:3,    # Summer\n",
    "                                           9:4, 10:4, 11:4}) # Fall\n",
    "    \n",
    "    # Create weekend flag\n",
    "    df['is_weekend'] = df['Date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Combine holiday information\n",
    "    df['is_any_holiday'] = ((df[['holiday_nl', 'holiday_be', 'holiday_de', \n",
    "                                'holiday_fr', 'holiday_gb', 'holiday_it']] == 1).any(axis=1)).astype(int)\n",
    "    \n",
    "    # Create tourism pressure indicator\n",
    "    df['tourism_pressure'] = df['hotel_occupancy_index'] * df['tourism_season_strength']\n",
    "    \n",
    "    # lagged features for strong predictors\n",
    "    for col in ['Recreatief NL', 'Recreatief Buitenland', 'VO', 'Student']:\n",
    "        df[f'{col}_lag7'] = df[col].shift(7)\n",
    "        df[f'{col}_lag14'] = df[col].shift(14)\n",
    "    \n",
    "    # rolling means for key metrics\n",
    "    for col in ['nemo_market_share', 'hotel_occupancy_index', 'tourism_season_strength']:\n",
    "        df[f'{col}_7day_avg'] = df[col].rolling(7).mean()\n",
    "        df[f'{col}_30day_avg'] = df[col].rolling(30).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_weather_features(df):\n",
    "    # Create weather condition categories\n",
    "    df['is_good_weather'] = ((df['MeanTemp_C'] > 15) & \n",
    "                            (df['Precipitation_mm'] < 1) & \n",
    "                            (df['Sunshine_hours'] > 4)).astype(int)\n",
    "    \n",
    "    # Create extreme weather indicators\n",
    "    df['is_rainy_day'] = (df['Precipitation_mm'] > 5).astype(int)\n",
    "    df['is_very_hot'] = (df['MeanTemp_C'] > 25).astype(int)\n",
    "    \n",
    "    # Create weather-season interaction\n",
    "    df['weather_season_score'] = df['MeanTemp_C'] * df['tourism_season_strength']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_time_features(df):\n",
    "    # Create holiday season flags\n",
    "    df['is_summer_holiday'] = ((df['Date'].dt.month.isin([7, 8])) & (df['school_holiday'] == 1)).astype(int)\n",
    "    \n",
    "    # Create peak hours/days indicators\n",
    "    df['is_peak_month'] = df['Date'].dt.month.isin([7, 8, 12]).astype(int)\n",
    "    \n",
    "    # Create cyclical features for month and day of week\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['Date'].dt.month/12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['Date'].dt.month/12)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['Date'].dt.dayofweek/7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['Date'].dt.dayofweek/7)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_modeling(df):\n",
    "    df = engineer_advanced_features(df)\n",
    "    df = enhance_weather_features(df)\n",
    "    df = enhance_time_features(df)\n",
    "    \n",
    "    # Handle missing values in new features\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "df = preprocess_for_modeling(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_numerical(X):\n",
    "    X_processed = X.copy()\n",
    "    \n",
    "    # Convert date column to numerical features\n",
    "    if 'Date' in X_processed.columns:\n",
    "        X_processed['Date'] = pd.to_datetime(X_processed['Date'])\n",
    "        X_processed['year'] = X_processed['Date'].dt.year\n",
    "        X_processed['month'] = X_processed['Date'].dt.month\n",
    "        X_processed['day'] = X_processed['Date'].dt.day\n",
    "        X_processed['dayofweek'] = X_processed['Date'].dt.dayofweek\n",
    "        X_processed = X_processed.drop('Date', axis=1)\n",
    "    \n",
    "    # Convert boolean columns to int\n",
    "    bool_columns = X_processed.select_dtypes(include=['bool']).columns\n",
    "    for col in bool_columns:\n",
    "        X_processed[col] = X_processed[col].astype(int)\n",
    "    \n",
    "    # Get only numeric columns\n",
    "    numeric_columns = X_processed.select_dtypes(include=['int64', 'float64']).columns\n",
    "    X_processed = X_processed[numeric_columns]\n",
    "    \n",
    "    return X_processed\n",
    "\n",
    "df_processed = prepare_data_for_mi(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_processed.corr()['Total_Visitors'].drop('Total_Visitors')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 18))\n",
    "correlations.sort_values().plot(kind='barh', ax=ax, color='blue')\n",
    "ax.axvline(x=0.4, color='red', linestyle='--')\n",
    "ax.axvline(x=-0.4, color='red', linestyle='--')\n",
    "ax.set_title('Feature Correlation with Total Visitors')\n",
    "ax.set_xlabel('Correlation Coefficient')\n",
    "ax.set_ylabel('Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_processed.drop(columns=[\"Total_Visitors\"])\n",
    "y = df_processed[\"Total_Visitors\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = mutual_info_regression(X_train, y_train)\n",
    "\n",
    "# Get mi scores\n",
    "mi_scores_series = pd.Series(mi_scores, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 18))\n",
    "mi_scores_series.plot(kind='barh', ax=ax, color='blue')\n",
    "ax.axvline(x=0.25, color='red', linestyle='--')\n",
    "ax.set_title('Feature Mutual info scores')\n",
    "ax.set_xlabel('Mutual info scores')\n",
    "ax.set_ylabel('Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total_Visitor demand prediciton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_column_mapping = {\n",
    "    'Total_Visitors': {\n",
    "        'target': 'Total_Visitors',\n",
    "        'exclude_columns': [\n",
    "            # Individual visitor types (since we're predicting their sum)\n",
    "            'Extern', 'PO', 'Recreatief Buitenland', 'Recreatief NL', \n",
    "            'Student', 'VO',\n",
    "            # Derived totals that include individual types\n",
    "            'recreational_total', 'education_total',\n",
    "            # Lag features of individual types (to avoid data leakage)\n",
    "            'Recreatief NL_lag7', 'Recreatief NL_lag14',\n",
    "            'Recreatief Buitenland_lag7', 'Recreatief Buitenland_lag14', \n",
    "            'VO_lag7', 'VO_lag14', 'Student_lag7', 'Student_lag14'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'Extern': {\n",
    "        'target': 'Extern',\n",
    "        'exclude_columns': [\n",
    "            # Other visitor types and totals\n",
    "            'PO', 'Recreatief Buitenland', 'Recreatief NL', 'Student', 'VO',\n",
    "            'Total_Visitors', 'recreational_total', 'education_total',\n",
    "            # All lag features of other types\n",
    "            'Recreatief NL_lag7', 'Recreatief NL_lag14',\n",
    "            'Recreatief Buitenland_lag7', 'Recreatief Buitenland_lag14', \n",
    "            'VO_lag7', 'VO_lag14', 'Student_lag7', 'Student_lag14'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'PO': {\n",
    "        'target': 'PO',\n",
    "        'exclude_columns': [\n",
    "            'Extern', 'Recreatief Buitenland', 'Recreatief NL', 'Student', 'VO',\n",
    "            'Total_Visitors', 'recreational_total', 'education_total',\n",
    "            'Recreatief NL_lag7', 'Recreatief NL_lag14',\n",
    "            'Recreatief Buitenland_lag7', 'Recreatief Buitenland_lag14', \n",
    "            'VO_lag7', 'VO_lag14', 'Student_lag7', 'Student_lag14'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'Recreatief Buitenland': {\n",
    "        'target': 'Recreatief Buitenland',\n",
    "        'exclude_columns': [\n",
    "            'Extern', 'PO', 'Recreatief NL', 'Student', 'VO',\n",
    "            'Total_Visitors', 'recreational_total', 'education_total',\n",
    "            'Recreatief NL_lag7', 'Recreatief NL_lag14',\n",
    "            'VO_lag7', 'VO_lag14', 'Student_lag7', 'Student_lag14'\n",
    "            # Keep own lag features: 'Recreatief Buitenland_lag7', 'Recreatief Buitenland_lag14'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'Recreatief NL': {\n",
    "        'target': 'Recreatief NL',\n",
    "        'exclude_columns': [\n",
    "            'Extern', 'PO', 'Recreatief Buitenland', 'Student', 'VO',\n",
    "            'Total_Visitors', 'recreational_total', 'education_total',\n",
    "            'Recreatief Buitenland_lag7', 'Recreatief Buitenland_lag14', \n",
    "            'VO_lag7', 'VO_lag14', 'Student_lag7', 'Student_lag14'\n",
    "            # Keep own lag features: 'Recreatief NL_lag7', 'Recreatief NL_lag14'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'Student': {\n",
    "        'target': 'Student',\n",
    "        'exclude_columns': [\n",
    "            'Extern', 'PO', 'Recreatief Buitenland', 'Recreatief NL', 'VO',\n",
    "            'Total_Visitors', 'recreational_total', 'education_total',\n",
    "            'Recreatief NL_lag7', 'Recreatief NL_lag14',\n",
    "            'Recreatief Buitenland_lag7', 'Recreatief Buitenland_lag14', \n",
    "            'VO_lag7', 'VO_lag14'\n",
    "            # Keep own lag features: 'Student_lag7', 'Student_lag14'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'VO': {\n",
    "        'target': 'VO',\n",
    "        'exclude_columns': [\n",
    "            'Extern', 'PO', 'Recreatief Buitenland', 'Recreatief NL', 'Student',\n",
    "            'Total_Visitors', 'recreational_total', 'education_total',\n",
    "            'Recreatief NL_lag7', 'Recreatief NL_lag14',\n",
    "            'Recreatief Buitenland_lag7', 'Recreatief Buitenland_lag14', \n",
    "            'Student_lag7', 'Student_lag14'\n",
    "            # Keep own lag features: 'VO_lag7', 'VO_lag14'\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total_visitors = df_processed.drop(columns=[\"Total_Visitors\"] + model_column_mapping[\"Total_Visitors\"][\"exclude_columns\"])\n",
    "y_total_visitors = df_processed[\"Total_Visitors\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_total_visitors, y_total_visitors, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models \n",
    "models = [\n",
    "    (\"Ridge\", Ridge(), [StandardScaler(), MinMaxScaler()]),\n",
    "    (\"Lasso\", Lasso(), [StandardScaler(), MinMaxScaler()]),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor(random_state=42), [None]),\n",
    "    (\"XGBRegressor\", XGBRegressor(random_state=42), [StandardScaler(), MinMaxScaler()]),\n",
    "]\n",
    "\n",
    "# Parameter grids\n",
    "param_grids = {\n",
    "    \"Ridge\": {\n",
    "        \"model__alpha\": np.logspace(-3, 3, 20)\n",
    "    },\n",
    "    \"Lasso\": {\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        'model__max_iter': [5000, 10000],\n",
    "        'model__tol': [1e-6, 1e-5],\n",
    "        'model__selection': ['cyclic', 'random']\n",
    "    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"model__n_estimators\": [50, 100, 200],\n",
    "        \"model__max_depth\": [None, 10, 20, 30]\n",
    "    },\n",
    "    \"XGBRegressor\": {\n",
    "        \"model__n_estimators\": [100, 200, 500],\n",
    "        \"model__learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"model__max_depth\": [3, 4, 6],\n",
    "        \"model__min_child_weight\": [1, 3],\n",
    "        \"model__subsample\": [0.8, 0.9],\n",
    "        \"model__colsample_bytree\": [0.8, 0.9]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model, scaler=None):\n",
    "    \"\"\"Create a pipeline with optional scaler and model\"\"\"\n",
    "    if scaler is None:\n",
    "        return Pipeline([('model', model)])\n",
    "    else:\n",
    "        return Pipeline([('scaler', scaler), ('model', model)])\n",
    "\n",
    "\n",
    "def train_and_validate_models(X_train, X_test, y_train, y_test, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Train and validate all models with hyperparameter tuning\n",
    "    \n",
    "    Parameters:\n",
    "    X_train, X_test: Training and testing features\n",
    "    y_train, y_test: Training and testing targets\n",
    "    cv_folds: Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary containing results for all models\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    best_models = {}\n",
    "    \n",
    "    print(\"Starting model training and validation...\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for model_name, model, scalers in models:\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        model_results = []\n",
    "        \n",
    "        # Try different scalers for each model\n",
    "        for scaler in scalers:\n",
    "            scaler_name = type(scaler).__name__ if scaler else \"NoScaler\"\n",
    "            print(f\"  Testing with {scaler_name}...\")\n",
    "            \n",
    "            # Create pipeline\n",
    "            pipeline = create_pipeline(model, scaler)\n",
    "            \n",
    "            # Get parameter grid for this model\n",
    "            param_grid = param_grids.get(model_name, {})\n",
    "            \n",
    "            # Use RandomizedSearchCV for XGBoost due to large parameter space\n",
    "            if model_name == \"XGBRegressor\":\n",
    "                search = RandomizedSearchCV(\n",
    "                    pipeline, \n",
    "                    param_grid, \n",
    "                    cv=cv_folds, \n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    n_iter=50,  # Limit iterations for XGBoost\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            else:\n",
    "                search = GridSearchCV(\n",
    "                    pipeline, \n",
    "                    param_grid, \n",
    "                    cv=cv_folds, \n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            \n",
    "            # Fit the search\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred_train = search.predict(X_train)\n",
    "            y_pred_test = search.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "            test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "            train_r2 = r2_score(y_train, y_pred_train)\n",
    "            test_r2 = r2_score(y_test, y_pred_test)\n",
    "            train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "            test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "            \n",
    "            # Cross-validation score\n",
    "            cv_scores = cross_val_score(search.best_estimator_, X_train, y_train, \n",
    "                                      cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "            cv_rmse = np.sqrt(-cv_scores)\n",
    "            \n",
    "            result = {\n",
    "                'model_name': model_name,\n",
    "                'scaler': scaler_name,\n",
    "                'best_params': search.best_params_,\n",
    "                'best_cv_score': search.best_score_,\n",
    "                'train_mse': train_mse,\n",
    "                'test_mse': test_mse,\n",
    "                'train_rmse': np.sqrt(train_mse),\n",
    "                'test_rmse': np.sqrt(test_mse),\n",
    "                'train_r2': train_r2,\n",
    "                'test_r2': test_r2,\n",
    "                'train_mae': train_mae,\n",
    "                'test_mae': test_mae,\n",
    "                'cv_rmse_mean': cv_rmse.mean(),\n",
    "                'cv_rmse_std': cv_rmse.std(),\n",
    "                'best_estimator': search.best_estimator_\n",
    "            }\n",
    "            \n",
    "            model_results.append(result)\n",
    "            \n",
    "            print(f\"    Best CV Score: {search.best_score_:.4f}\")\n",
    "            print(f\"    Test RMSE: {np.sqrt(test_mse):.4f}\")\n",
    "            print(f\"    Test R²: {test_r2:.4f}\")\n",
    "        \n",
    "        # Find best scaler configuration for this model\n",
    "        best_config = min(model_results, key=lambda x: x['test_rmse'])\n",
    "        results[model_name] = model_results\n",
    "        best_models[model_name] = best_config\n",
    "        \n",
    "        print(f\"  Best configuration: {best_config['scaler']}\")\n",
    "        print(f\"  Best Test RMSE: {best_config['test_rmse']:.4f}\")\n",
    "    \n",
    "    return results, best_models\n",
    "\n",
    "def print_detailed_results(results, best_models):\n",
    "    \"\"\"Print detailed results for all models\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_data = []\n",
    "    for model_name, best_config in best_models.items():\n",
    "        summary_data.append({\n",
    "            'Model': model_name,\n",
    "            'Best Scaler': best_config['scaler'],\n",
    "            'Test RMSE': best_config['test_rmse'],\n",
    "            'Test R²': best_config['test_r2'],\n",
    "            'Test MAE': best_config['test_mae'],\n",
    "            'CV RMSE (mean±std)': f\"{best_config['cv_rmse_mean']:.4f}±{best_config['cv_rmse_std']:.4f}\"\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.sort_values('Test RMSE')\n",
    "    \n",
    "    print(\"\\nMODEL COMPARISON SUMMARY:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Find overall best model\n",
    "    best_overall = min(best_models.values(), key=lambda x: x['test_rmse'])\n",
    "    \n",
    "    print(f\"\\n🏆 BEST OVERALL MODEL:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Model: {best_overall['model_name']}\")\n",
    "    print(f\"Scaler: {best_overall['scaler']}\")\n",
    "    print(f\"Test RMSE: {best_overall['test_rmse']:.4f}\")\n",
    "    print(f\"Test R²: {best_overall['test_r2']:.4f}\")\n",
    "    print(f\"Test MAE: {best_overall['test_mae']:.4f}\")\n",
    "    print(f\"Best Parameters: {best_overall['best_params']}\")\n",
    "    \n",
    "    return best_overall\n",
    "\n",
    "def get_feature_importance(best_model, feature_names=None):\n",
    "    \"\"\"Extract feature importance from the best model if available\"\"\"\n",
    "    \n",
    "    model = best_model['best_estimator']\n",
    "    \n",
    "    # Get the actual model from pipeline\n",
    "    if hasattr(model, 'named_steps'):\n",
    "        actual_model = model.named_steps['model']\n",
    "    else:\n",
    "        actual_model = model\n",
    "    \n",
    "    if hasattr(actual_model, 'feature_importances_'):\n",
    "        importances = actual_model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            feature_imp = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importances\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\n📊 FEATURE IMPORTANCE ({best_model['model_name']}):\")\n",
    "            print(\"-\" * 40)\n",
    "            print(feature_imp.head(10).to_string(index=False))\n",
    "            \n",
    "            return feature_imp\n",
    "    \n",
    "    elif hasattr(actual_model, 'coef_'):\n",
    "        coefficients = actual_model.coef_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            feature_imp = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'coefficient': coefficients,\n",
    "                'abs_coefficient': np.abs(coefficients)\n",
    "            }).sort_values('abs_coefficient', ascending=False)\n",
    "            \n",
    "            print(f\"\\n📊 FEATURE COEFFICIENTS ({best_model['model_name']}):\")\n",
    "            print(\"-\" * 45)\n",
    "            print(feature_imp.head(10).to_string(index=False))\n",
    "            \n",
    "            return feature_imp\n",
    "    \n",
    "    print(f\"\\nFeature importance not available for {best_model['model_name']}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate models\n",
    "results, best_models = train_and_validate_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print detailed results\n",
    "best_overall = print_detailed_results(results, best_models)\n",
    "\n",
    "# Access the best trained model\n",
    "best_trained_model = best_overall['best_estimator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETAILED RESULTS\n",
    "\n",
    "MODEL COMPARISON SUMMARY:\n",
    "\n",
    "                Model    Best Scaler  Test RMSE  Test R²   Test MAE CV RMSE (mean±std)\n",
    "         XGBRegressor   MinMaxScaler 659.760270 0.728583 495.026963   618.6914±53.8980\n",
    "RandomForestRegressor       NoScaler 667.275439 0.722364 497.114843   635.7325±59.0288\n",
    "                Ridge StandardScaler 872.830283 0.524966 661.598681   772.1244±64.4633\n",
    "                Lasso   MinMaxScaler 880.415731 0.516673 668.878415   774.8332±65.2600\n",
    "\n",
    "🏆 BEST OVERALL MODEL:\n",
    "\n",
    "Model: XGBRegressor\n",
    "Scaler: MinMaxScaler\n",
    "Test RMSE: 659.7603\n",
    "Test R²: 0.7286\n",
    "Test MAE: 495.0270\n",
    "Best Parameters: {'model__subsample': 0.8, 'model__n_estimators': 100, 'model__min_child_weight': 3, 'model__max_depth': 6, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitor demand per type prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for visitor_type in visitor_types:\n",
    "    print(\"-\"*50)\n",
    "    print(visitor_type)\n",
    "    X = df_processed.drop(columns=[visitor_type] + model_column_mapping[visitor_type][\"exclude_columns\"])\n",
    "    y = df_processed[visitor_type]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40)\n",
    "\n",
    "    # Train and validate models\n",
    "    results, best_models = train_and_validate_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Print detailed results\n",
    "    best_overall = print_detailed_results(results, best_models)\n",
    "\n",
    "    # Access the best trained model\n",
    "    best_trained_model = best_overall['best_estimator']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extern\n",
    "🏆 BEST OVERALL MODEL:\n",
    "Model: Ridge\n",
    "Scaler: StandardScaler\n",
    "Test RMSE: 97.7306\n",
    "Test R²: 0.0068\n",
    "Test MAE: 22.8596\n",
    "Best Parameters: {'model__alpha': 233.57214690901213}\n",
    "\n",
    "================================================================================\n",
    "\n",
    "PO\n",
    "🏆 BEST OVERALL MODEL:\n",
    "Model: RandomForestRegressor\n",
    "Scaler: NoScaler\n",
    "Test RMSE: 58.2827\n",
    "Test R²: 0.5088\n",
    "Test MAE: 41.4976\n",
    "Best Parameters: {'model__max_depth': 10, 'model__n_estimators': 200}\n",
    "\n",
    "================================================================================\n",
    "\n",
    "Recreatief Buitenland\n",
    "🏆 BEST OVERALL MODEL:\n",
    "Model: XGBRegressor\n",
    "Scaler: StandardScaler\n",
    "Test RMSE: 254.5829\n",
    "Test R²: 0.7323\n",
    "Test MAE: 186.6319\n",
    "Best Parameters: {'model__subsample': 0.9, 'model__n_estimators': 500, 'model__min_child_weight': 1, 'model__max_depth': 4, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.9}\n",
    "\n",
    "================================================================================\n",
    "\n",
    "Recreatief NL\n",
    "🏆 BEST OVERALL MODEL:\n",
    "Model: XGBRegressor\n",
    "Scaler: StandardScaler\n",
    "Test RMSE: 621.0990\n",
    "Test R²: 0.6215\n",
    "Test MAE: 418.0994\n",
    "Best Parameters: {'model__subsample': 0.8, 'model__n_estimators': 500, 'model__min_child_weight': 3, 'model__max_depth': 6, 'model__learning_rate': 0.01, 'model__colsample_bytree': 0.9}\n",
    "\n",
    "================================================================================\n",
    "\n",
    "Student\n",
    "🏆 BEST OVERALL MODEL:\n",
    "Model: XGBRegressor\n",
    "Scaler: StandardScaler\n",
    "Test RMSE: 33.3323\n",
    "Test R²: 0.4473\n",
    "Test MAE: 26.0796\n",
    "Best Parameters: {'model__subsample': 0.8, 'model__n_estimators': 500, 'model__min_child_weight': 1, 'model__max_depth': 3, 'model__learning_rate': 0.01, 'model__colsample_bytree': 0.9}\n",
    "\n",
    "================================================================================\n",
    "\n",
    "VO\n",
    "🏆 BEST OVERALL MODEL:\n",
    "Model: XGBRegressor\n",
    "Scaler: StandardScaler\n",
    "Test RMSE: 74.4476\n",
    "Test R²: 0.2887\n",
    "Test MAE: 51.0027\n",
    "Best Parameters: {'model__subsample': 0.8, 'model__n_estimators': 500, 'model__min_child_weight': 1, 'model__max_depth': 4, 'model__learning_rate': 0.01, 'model__colsample_bytree': 0.9}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
